{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt/bCNJCmj3MmjWY0xA0hQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chirag314/Cancerdata-ensemble-model/blob/main/Cancerdata_Ensemble_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###This notebook is copied from exercises from book Ensemble Machine Learning Cookbook."
      ],
      "metadata": {
        "id": "de3ggC8Kv_99"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rror9ooAv2jU",
        "outputId": "d3caab0e-c06f-4526-f1c0-641d340616c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0  87139402         B        12.32         12.39           78.85      464.1   \n",
            "1   8910251         B        10.60         18.95           69.28      346.4   \n",
            "2    905520         B        11.04         16.83           70.92      373.2   \n",
            "3    868871         B        11.28         13.39           73.00      384.8   \n",
            "4   9012568         B        15.19         13.21           97.65      711.8   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  points_mean  \\\n",
            "0          0.10280           0.06981         0.03987      0.03700   \n",
            "1          0.09688           0.11470         0.06387      0.02642   \n",
            "2          0.10770           0.07804         0.03046      0.02480   \n",
            "3          0.11640           0.11360         0.04635      0.04796   \n",
            "4          0.07963           0.06934         0.03393      0.02657   \n",
            "\n",
            "   symmetry_mean  dimension_mean  radius_se  texture_se  perimeter_se  \\\n",
            "0         0.1959         0.05955     0.2360      0.6656         1.670   \n",
            "1         0.1922         0.06491     0.4505      1.1970         3.430   \n",
            "2         0.1714         0.06340     0.1967      1.3870         1.342   \n",
            "3         0.1771         0.06072     0.3384      1.3430         1.851   \n",
            "4         0.1721         0.05544     0.1783      0.4125         1.338   \n",
            "\n",
            "   area_se  smoothness_se  compactness_se  concavity_se  points_se  \\\n",
            "0    17.43       0.008045        0.011800       0.01683   0.012410   \n",
            "1    27.10       0.007470        0.035810       0.03354   0.013650   \n",
            "2    13.54       0.005158        0.009355       0.01056   0.007483   \n",
            "3    26.33       0.011270        0.034980       0.02187   0.019650   \n",
            "4    17.72       0.005012        0.014850       0.01551   0.009155   \n",
            "\n",
            "   symmetry_se  dimension_se  radius_worst  texture_worst  perimeter_worst  \\\n",
            "0      0.01924      0.002248         13.50          15.64            86.97   \n",
            "1      0.03504      0.003318         11.88          22.94            78.28   \n",
            "2      0.01718      0.002198         12.41          26.44            79.93   \n",
            "3      0.01580      0.003442         11.92          15.77            76.53   \n",
            "4      0.01647      0.001767         16.20          15.73           104.50   \n",
            "\n",
            "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
            "0       549.1            0.1385             0.1266          0.12420   \n",
            "1       424.8            0.1213             0.2515          0.19160   \n",
            "2       471.4            0.1369             0.1482          0.10670   \n",
            "3       434.0            0.1367             0.1822          0.08669   \n",
            "4       819.1            0.1126             0.1737          0.13620   \n",
            "\n",
            "   points_worst  symmetry_worst  dimension_worst  \n",
            "0       0.09391          0.2827          0.06771  \n",
            "1       0.07926          0.2940          0.07587  \n",
            "2       0.07431          0.2998          0.07881  \n",
            "3       0.08611          0.2102          0.06784  \n",
            "4       0.08178          0.2487          0.06766  \n"
          ]
        }
      ],
      "source": [
        "# Read data from github. Use raw format and copy url# Note normal url and raw url will be different.\n",
        "import pandas as pd\n",
        "pd.options.display.max_rows=None\n",
        "pd.options.display.max_columns=None\n",
        "url = 'https://raw.githubusercontent.com/PacktPublishing/Ensemble-Machine-Learning-Cookbook/master/Chapter02/wisc_bc_data.csv'\n",
        "df_cancerdata = pd.read_csv(url)\n",
        "#df = pd.read_csv(url)\n",
        "print(df_cancerdata.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Here, we have a dataset based on the properties of cancerous tumors. Using this dataset, we'll build multiple classification models with diagnosis as our response variable. The diagnosis variable has the values, B and M, which indicate whether the tumor is benign or malignant. With multiple learners, we extract multiple predictions. The weighted averaging technique takes the average of all of the predicted values for each training sample."
      ],
      "metadata": {
        "id": "Fhig-YINwrKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n"
      ],
      "metadata": {
        "id": "uuEy1KqUwmP_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test cample from our dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create feature and response state\n",
        "#feature_columns=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide', 'total sulfur dioxide','density', 'pH','sulphates', 'alcohol']\n",
        "X=df_cancerdata.iloc[:,2:32]\n",
        "y=df_cancerdata['diagnosis']\n",
        "\n",
        "# Create train and test results\n",
        "X_train, X_test, Y_train, Y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
      ],
      "metadata": {
        "id": "Co9qf7bqxDyn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the sub models\n",
        "estimators = []\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "estimators.append(('DecisionTree', dt_model))\n",
        "\n",
        "svm_model = SVC(probability=True)\n",
        "estimators.append(('SupportVector', svm_model))\n",
        "\n",
        "logit_model = LogisticRegression()\n",
        "estimators.append(('Logistic Regression', logit_model))"
      ],
      "metadata": {
        "id": "TJPXAsTNr5qr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_model.fit(X_train, Y_train)\n",
        "svm_model.fit(X_train, Y_train)\n",
        "logit_model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "WwB4s5gSyNBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8bd9801-50a4-4ddf-91cd-8ff5dd0a9f2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the predict_proba() function to predict the class probabilities:\n",
        "dt_predictions=dt_model.predict_proba(X_test)\n",
        "svm_predictions=svm_model.predict_proba(X_test)\n",
        "logit_predictions=logit_model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "fb_7lU75yxxk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assign different weights to each of the models to get our final predictions:\n",
        "weighted_average_predictions=(dt_predictions * 0.3 + svm_predictions * 0.4 + logit_predictions * 0.3)"
      ],
      "metadata": {
        "id": "kJ1izYUlzcCt"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}